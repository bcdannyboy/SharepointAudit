"""
Performance-Optimized SharePoint Audit Dashboard
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta, timezone
import asyncio
import json
import io
import re
from typing import Dict, List, Optional, Any
import numpy as np

# Import local modules
from database.repository import DatabaseRepository
from dashboard.utils import format_bytes, format_number

# Page configuration
st.set_page_config(
    page_title="SharePoint Audit Dashboard (Optimized)",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize session state
if 'filters' not in st.session_state:
    st.session_state.filters = {}
if 'selected_tab' not in st.session_state:
    st.session_state.selected_tab = "Overview"
if 'data_sample_size' not in st.session_state:
    st.session_state.data_sample_size = 50000
if 'loaded_data' not in st.session_state:
    st.session_state.loaded_data = None

# Helper functions for data enrichment
def _safe_object_id_to_int(object_id):
    """Safely convert object_id (which may be a composite SharePoint ID) to integer for indexing purposes."""
    if object_id is None:
        return 0

    # Convert to string and use hash to get a consistent integer
    # Use abs() to ensure positive number and modulo to keep it reasonable
    return abs(hash(str(object_id))) % (10**9)

def get_database_stats(db_path: str) -> Dict[str, int]:
    """Get quick database statistics without loading all data."""
    async def _get_stats():
        repo = DatabaseRepository(db_path)

        # Get counts for each table
        stats = {}

        # Permissions count
        perm_result = await repo.fetch_one("SELECT COUNT(*) as count FROM permissions")
        stats['total_permissions'] = perm_result['count'] if perm_result else 0

        # Sites count
        sites_result = await repo.fetch_one("SELECT COUNT(*) as count FROM sites")
        stats['total_sites'] = sites_result['count'] if sites_result else 0

        # Files count
        files_result = await repo.fetch_one("SELECT COUNT(*) as count FROM files")
        stats['total_files'] = files_result['count'] if files_result else 0

        # Get permission type breakdown
        perm_types_query = """
        SELECT object_type, COUNT(*) as count
        FROM permissions
        GROUP BY object_type
        ORDER BY count DESC
        """
        perm_types = await repo.fetch_all(perm_types_query)
        stats['permission_types'] = {row['object_type']: row['count'] for row in perm_types}

        return stats

    return asyncio.run(_get_stats())

@st.cache_data(ttl=300)
def load_sampled_permissions_data(db_path: str, sample_size: int = 50000) -> pd.DataFrame:
    """Load a sample of permissions data for dashboard display."""
    async def _load():
        repo = DatabaseRepository(db_path)

        # Use TABLESAMPLE or LIMIT with ORDER BY RANDOM() for sampling
        # SQLite doesn't have TABLESAMPLE, so we'll use a combination approach
        query = f"""
        SELECT
            p.*
        FROM permissions p
        ORDER BY RANDOM()
        LIMIT {sample_size}
        """

        results = await repo.fetch_all(query)

        if not results:
            return pd.DataFrame()

        df = pd.DataFrame(results)

        # Convert datetime columns
        datetime_columns = ['granted_at', 'modified_at']
        for col in datetime_columns:
            if col in df.columns and not df.empty:
                df[col] = pd.to_datetime(df[col], utc=True, errors='coerce')

        # Add basic enrichments (simplified for performance)
        if not df.empty:
            # Add basic site URLs - use a simplified lookup
            site_lookup_query = """
            SELECT site_id, url, title
            FROM sites
            WHERE site_id IN (
                SELECT DISTINCT object_id
                FROM permissions
                WHERE object_type = 'site'
                ORDER BY RANDOM()
                LIMIT 1000
            )
            """
            site_data = await repo.fetch_all(site_lookup_query)
            site_lookup = {row['site_id']: row['url'] for row in site_data}

            # Simple site URL assignment based on object_id
            df['site_url'] = df.apply(lambda row:
                site_lookup.get(row['object_id'], f"https://sharepoint.com/sites/Site_{_safe_object_id_to_int(row['object_id']) % 100}"),
                axis=1
            )

            # Simple object name generation
            df['object_name'] = df.apply(lambda row:
                f"{row['object_type'].title()}_{_safe_object_id_to_int(row['object_id']) % 1000}",
                axis=1
            )

            # Add risk scoring (simplified)
            df['risk_score'] = df.apply(lambda row:
                (30 if row.get('is_external', False) else 0) +
                (40 if row.get('is_anonymous_link', False) else 0) +
                (20 if row.get('permission_level') == 'Full Control' else 0),
                axis=1
            )

            df['risk_level'] = df['risk_score'].apply(lambda x:
                'Critical' if x >= 60 else
                'High' if x >= 40 else
                'Medium' if x >= 20 else 'Low'
            )

            # Add domain extraction
            df['principal_domain'] = df['principal_name'].apply(lambda x:
                x.split('@')[-1].lower() if '@' in str(x) else "Internal"
            )
            df['site_domain'] = df['site_url'].apply(lambda x:
                x.split('/')[2] if '://' in str(x) else "Unknown"
            )

        return df

    return asyncio.run(_load())

def render_performance_controls():
    """Render performance and data controls."""
    st.sidebar.header("âš¡ Performance Controls")

    # Sample size control
    sample_size = st.sidebar.slider(
        "Data Sample Size",
        min_value=1000,
        max_value=500000,
        value=st.session_state.data_sample_size,
        step=5000,
        help="Larger samples provide more accurate data but take longer to load"
    )

    # Reload data button
    if st.sidebar.button("ğŸ”„ Reload Data") or sample_size != st.session_state.data_sample_size:
        st.session_state.data_sample_size = sample_size
        st.session_state.loaded_data = None
        st.rerun()

    return sample_size

def render_overview_tab_optimized(df: pd.DataFrame, stats: Dict[str, int]):
    """Render optimized overview tab."""
    st.header("ğŸ“Š Overview (Performance Optimized)")

    # Database statistics
    st.subheader("ğŸ“ˆ Database Statistics")
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        st.metric("Total Permissions", f"{stats['total_permissions']:,}")
    with col2:
        st.metric("Total Sites", f"{stats['total_sites']:,}")
    with col3:
        st.metric("Total Files", f"{stats['total_files']:,}")
    with col4:
        st.metric("Sample Size", f"{len(df):,}")

    # Sample data metrics
    if not df.empty:
        st.subheader("ğŸ“Š Sample Data Analysis")
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            unique_principals = df['principal_name'].nunique()
            st.metric("Unique Principals (Sample)", f"{unique_principals:,}")

        with col2:
            external_users = df[df['is_external'] == True]['principal_name'].nunique()
            st.metric("External Users (Sample)", f"{external_users:,}")

        with col3:
            critical_risks = len(df[df['risk_level'] == 'Critical'])
            st.metric("Critical Risks (Sample)", f"{critical_risks:,}")

        with col4:
            high_risks = len(df[df['risk_level'] == 'High'])
            st.metric("High Risks (Sample)", f"{high_risks:,}")

        # Charts
        col1, col2 = st.columns(2)

        with col1:
            # Permission distribution
            if 'permission_level' in df.columns:
                perm_dist = df['permission_level'].value_counts()
                fig = px.pie(values=perm_dist.values, names=perm_dist.index,
                           title="Permission Level Distribution (Sample)")
                st.plotly_chart(fig, use_container_width=True)

        with col2:
            # Object type distribution
            if 'object_type' in df.columns:
                obj_dist = df['object_type'].value_counts()
                fig = px.bar(x=obj_dist.values, y=obj_dist.index, orientation='h',
                           title="Permissions by Object Type (Sample)")
                st.plotly_chart(fig, use_container_width=True)

        # Risk level distribution
        if 'risk_level' in df.columns:
            risk_dist = df['risk_level'].value_counts()
            colors = {'Critical': 'red', 'High': 'orange', 'Medium': 'yellow', 'Low': 'green'}
            fig = px.bar(x=risk_dist.index, y=risk_dist.values,
                        title="Risk Level Distribution (Sample)",
                        color=risk_dist.index,
                        color_discrete_map=colors)
            st.plotly_chart(fig, use_container_width=True)

def render_data_explorer_tab(df: pd.DataFrame):
    """Render data explorer tab for detailed analysis."""
    st.header("ğŸ” Data Explorer")

    if df.empty:
        st.warning("No data loaded. Please reload data from the sidebar.")
        return

    # Filters
    st.subheader("ğŸ›ï¸ Filters")
    col1, col2, col3 = st.columns(3)

    with col1:
        object_types = st.multiselect("Object Types", df['object_type'].unique())
    with col2:
        permission_levels = st.multiselect("Permission Levels", df['permission_level'].unique())
    with col3:
        risk_levels = st.multiselect("Risk Levels", df['risk_level'].unique())

    # Apply filters
    filtered_df = df.copy()
    if object_types:
        filtered_df = filtered_df[filtered_df['object_type'].isin(object_types)]
    if permission_levels:
        filtered_df = filtered_df[filtered_df['permission_level'].isin(permission_levels)]
    if risk_levels:
        filtered_df = filtered_df[filtered_df['risk_level'].isin(risk_levels)]

    # Display filtered results
    st.subheader(f"ğŸ“‹ Filtered Results ({len(filtered_df):,} records)")

    # Column selection for display
    available_columns = filtered_df.columns.tolist()
    default_columns = ['object_type', 'object_name', 'principal_name', 'permission_level', 'risk_level']
    display_columns = st.multiselect(
        "Select columns to display",
        available_columns,
        default=[col for col in default_columns if col in available_columns]
    )

    if display_columns:
        # Pagination
        page_size = st.selectbox("Records per page", [100, 500, 1000, 2000], index=1)
        total_pages = (len(filtered_df) + page_size - 1) // page_size

        if total_pages > 1:
            page = st.selectbox("Page", range(1, total_pages + 1))
            start_idx = (page - 1) * page_size
            end_idx = start_idx + page_size
            page_df = filtered_df.iloc[start_idx:end_idx]
        else:
            page_df = filtered_df

        # Display data
        st.dataframe(page_df[display_columns], use_container_width=True)

        # Download option
        csv = filtered_df[display_columns].to_csv(index=False)
        st.download_button(
            label="ğŸ“¥ Download filtered data as CSV",
            data=csv,
            file_name=f"sharepoint_audit_sample_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )

def main():
    """Main dashboard function."""
    st.title("ğŸš€ SharePoint Audit Dashboard (Optimized)")

    # Performance warning
    st.info("ğŸš€ **Performance Mode**: This dashboard loads a sample of your data for fast performance. Use the sidebar controls to adjust sample size.")

    # Database path
    db_path = st.session_state.get('db_path', 'audit.db')

    # Performance controls
    sample_size = render_performance_controls()

    try:
        # Get database statistics (fast)
        with st.spinner("Getting database statistics..."):
            stats = get_database_stats(db_path)

        # Display database size warning if needed
        if stats['total_permissions'] > 1000000:
            st.warning(f"âš ï¸ Large database detected: {stats['total_permissions']:,} total permissions. Using sampling for performance.")

        # Load sample data
        if st.session_state.loaded_data is None:
            with st.spinner(f"Loading sample data ({sample_size:,} records)..."):
                df = load_sampled_permissions_data(db_path, sample_size)
                st.session_state.loaded_data = df
        else:
            df = st.session_state.loaded_data

        # Tab selection
        tab1, tab2 = st.tabs(["ğŸ“Š Overview", "ğŸ” Data Explorer"])

        with tab1:
            render_overview_tab_optimized(df, stats)

        with tab2:
            render_data_explorer_tab(df)

    except Exception as e:
        st.error(f"Error loading data: {str(e)}")
        st.info("ğŸ’¡ Try reducing the sample size in the sidebar or check if the database file exists.")

if __name__ == "__main__":
    main()
